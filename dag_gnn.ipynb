{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUu8dBxf_l7_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgR82ZRGhU_6"
   },
   "outputs": [],
   "source": [
    "def identity_transpose(A):\n",
    "    '''Calculate (I - A^T)'''\n",
    "    return tf.eye(A.shape[0], A.shape[0]) - tf.transpose(A)\n",
    "\n",
    "def identity_transpose_inverse(A):\n",
    "    '''Calculate (I - A^T)^(-1)'''\n",
    "    return tf.linalg.inv(identity_transpose(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeHoXOg2DzRU"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    '''\n",
    "    Encoder class for DAG-GNN method\n",
    "\n",
    "    Inputs:\n",
    "    adjA (tensor [d, d]) : current estimated adjascency matrix\n",
    "    ind_dim (int) : dimension of input layer\n",
    "    out_dim (int) : dimension of output layer\n",
    "    hid_dim (int) : dimension of hidden layer\n",
    "\n",
    "    Outputs:\n",
    "    out (tensor [batch, d]) : output of neural network\n",
    "    ligs (tensor [d, d]) : product of (I - A^T @ out)\n",
    "    adjA (tensor [d, d]) : current estimated adjascency matrix\n",
    "\n",
    "    '''\n",
    "    def __init__(self, adjA, in_dim, hid_dim, out_dim):\n",
    "        super(MLPEncoder, self).__init__()\n",
    "        self.adjA = tf.Variable(initial_value = adjA, trainable = True)\n",
    "        self.Wa = tf.variable(np.zeros(), trainable = True)\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(hid_dim, activation= 'relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(out_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        '''Forward process of neural network'''\n",
    "        #calculate I - A^T\n",
    "        I_adjA = identity_transpose(self.adjA)\n",
    "        hidden = self.fc1(inputs)\n",
    "        out = self.fc2(hidden)\n",
    "        logits = tf.matmul(I_adj, out)\n",
    "        return out, logits, self.adjA\n",
    "\n",
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    '''\n",
    "    Decoder class for DAG-GNN method\n",
    "\n",
    "    Inputs:\n",
    "    ind_dim (int) : dimension of input layer\n",
    "    out_dim (int) : dimension of output layer\n",
    "    hid_dim (int) : dimension of hidden layer\n",
    "\n",
    "    Outputs:\n",
    "    '''\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(hid_dim, activation = 'relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(out_dim)\n",
    "\n",
    "    def call(self, inputs,  adjA):\n",
    "\n",
    "        #calculate (I - A^T)^(-1)\n",
    "        I_adjA = identity_transpose(adjA)\n",
    "        z = tf.matmul(I_adjA, inputs)\n",
    "\n",
    "        hidden = self.fc1(z)\n",
    "        out = self.fc2(hidden)\n",
    "        return z, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1X2jo0-Szr61"
   },
   "outputs": [],
   "source": [
    "def dag_gnn(data, hid_dim = 20, out_dim = 4, max_iter = 10e8, rho_max = 10e20, epochs = 20):\n",
    "    '''\n",
    "    Function for inference of DAG with method DAG-GNN\n",
    "    \n",
    "    Inputs:\n",
    "    \n",
    "    Outputs:\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    n_variables = data.shape[1]\n",
    "    rho = 1\n",
    "    alpha = 1\n",
    "    \n",
    "    def _h(A):\n",
    "    '''Calculate the constraint of A ensure that it's a DAG'''\n",
    "    #(Yu et al. 2019 DAG-GNN)\n",
    "    # h(w) = tr[(I + kA*A)^n_variables] - n_variables\n",
    "    M = tf.eye(n_variables, num_columns = n_variables) + A/n_variables\n",
    "    E = M\n",
    "    for _ in range(n_variables - 2):\n",
    "        E = tf.linalg.matmul(E, M)\n",
    "    h = tf.math.reduce_sum(tf.transpose(E) * M) - n_variables\n",
    "    return h\n",
    "\n",
    "    def _nll_loss(y_est, y):\n",
    "    '''\n",
    "    Compute negative likelihood loss for the adjacency matrix\n",
    "    L = (y_est - y)^2 / (2 * n)\n",
    "    '''\n",
    "    nll = tf.pow(y_test - y, 2) / (2 * n_variables)\n",
    "    return tf.sum(nll)\n",
    "\n",
    "    def _kl_loss(y):\n",
    "    '''Compute KL divergence loss'''\n",
    "    return tf.sum(tf.pow(y, 2) / ( 2 * y.shape[0]))\n",
    "\n",
    "    def _loss(A, A_est, logits):\n",
    "    '''\n",
    "    Function that evaluate the model loss\n",
    "    loss = kl loss + nll loss + dag constraint + l1 reg + l2 reg\n",
    "    '''\n",
    "        h = _h(A)\n",
    "        h_loss = 0.5 * rho * h * h + alpha * h\n",
    "        kl_loss = _kl_loss(logits)\n",
    "        nll_loss = _nll_loss(A_est, A)\n",
    "        return loss\n",
    "        \n",
    "    \n",
    "    new_adj = np.zeros((n_variables, n_variables))\n",
    "    #setup of data loader\n",
    "    train_loader, test_loader = setup_data_loader(data)\n",
    "    \n",
    "    #setup of neural networks\n",
    "    encoder = Encoder(new_adj, n_variables, hid_dim, out_dim)\n",
    "    decoder = Decoder(out_dim, hid_dim, n_variables)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        while rho < rho_max:\n",
    "            for epoch in range(epochs):\n",
    "                W_est = train()\n",
    "                \n",
    "    for batch_id, batch_data in enumarete(train_loader):\n",
    "        \n",
    "        #passing through neural network\n",
    "        encoder_out, logits, adjA = encoder(batch_data)\n",
    "        z, decoder_out = decoder(logits, adjA)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dag-gnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
